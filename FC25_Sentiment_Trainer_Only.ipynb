{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20297e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸŽ“ FC25 Sentiment Training Notebook\n",
    "\n",
    "# âœ… STEP 1: Upload Labeled Data\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Upload one or both of the following:\n",
    "# - labeled_comments.csv\n",
    "# - corrected_sentiment_batch.csv\n",
    "\n",
    "# âœ… STEP 2: Load and Merge Labeled Data\n",
    "import pandas as pd\n",
    "\n",
    "df_list = []\n",
    "\n",
    "if \"labeled_comments.csv\" in uploaded:\n",
    "    df1 = pd.read_csv(\"labeled_comments.csv\")\n",
    "    if \"Corrected Sentiment\" in df1.columns:\n",
    "        df1 = df1.rename(columns={\"Corrected Sentiment\": \"Sentiment\"})\n",
    "    df_list.append(df1)\n",
    "\n",
    "if \"corrected_sentiment_batch.csv\" in uploaded:\n",
    "    df2 = pd.read_csv(\"corrected_sentiment_batch.csv\")\n",
    "    if \"Corrected Sentiment\" in df2.columns:\n",
    "        df2 = df2.rename(columns={\"Corrected Sentiment\": \"Sentiment\"})\n",
    "    df_list.append(df2)\n",
    "\n",
    "if not df_list:\n",
    "    raise Exception(\"Please upload at least one labeled data file.\")\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df = df[df[\"Sentiment\"].isin([\"Positive\", \"Negative\", \"Neutral\"])]\n",
    "df = df.drop_duplicates(subset=[\"Comment\"])\n",
    "\n",
    "# âœ… STEP 3: Train Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"Comment\"], df[\"Sentiment\"], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# âœ… STEP 4: Evaluate\n",
    "y_pred = model.predict(X_test_vec)\n",
    "print(\"Model Evaluation Report:\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# âœ… STEP 5: Export Trained Model and Vectorizer\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "files.download(\"model.pkl\")\n",
    "files.download(\"vectorizer.pkl\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
